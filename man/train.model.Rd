% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_model.r
\name{train.model}
\alias{train.model}
\title{Model training}
\usage{
train.model(siamcat, method = c("lasso", "enet", "ridge", "lasso_ll",
  "ridge_ll", "randomForest"), stratify = TRUE, modsel.crit = list("auc"),
  min.nonzero.coeff = 1, param.set = NULL, verbose = 1)
}
\arguments{
\item{siamcat}{object of class \link{siamcat-class}}

\item{method}{string, specifies the type of model to be trained, may be one
of these: \code{c('lasso', 'enet', 'ridge', 'lasso_ll', 'ridge_ll',
'randomForest')}}

\item{stratify}{boolean, should the folds in the internal cross-validation be
stratified?, defaults to \code{TRUE}}

\item{modsel.crit}{list, specifies the model selection criterion during
internal cross-validation, may contain these: \code{c('auc', 'f1',
'acc', 'pr')}, defaults to \code{list('auc')}}

\item{min.nonzero.coeff}{integer number of minimum nonzero coefficients that
should be present in the model (only for \code{'lasso'},
\code{'ridge'}, and \code{'enet'}, defaults to \code{1}}

\item{param.set}{a list of extra parameters for mlr run, may contain:
\itemize{
  \item \code{cost} - for lasso_ll and ridge_ll
  \item \code{alpha} for enet
  \item \code{ntree} and \code{mtry} for RandomForrest.
} Defaults to \code{NULL}}

\item{verbose}{control output: \code{0} for no output at all, \code{1}
for only information about progress and success, \code{2} for normal
level of information and \code{3} for full debug information,
defaults to \code{1}}
}
\value{
object of class \link{siamcat-class} with added \code{model_list}
}
\description{
This function trains the a machine learning model on the
     training data
}
\details{
This functions performs the training of the machine learning model
     and functions as an interface to the \code{mlr}-package.

     The function expects a \link{siamcat-class}-object with a prepared
     cross-validation (see \link{create.data.split}) in the
     \code{data_split}-slot of the object. It then trains a model for
     each fold of the datasplit.

     For the machine learning methods that require additional
     hyperparameters (e.g. \code{lasso_ll}), the optimal hyperparameters
     are tuned with the function \link[mlr]{tuneParams} within the
     \code{mlr}-package.

     The methods \code{'lasso'}, \code{'enet'}, and \code{'ridge'} are
     implemented as mlr-taks using the \code{'classif.cvglmnet'} Learner,
     \code{'lasso_ll'} and \code{'ridge_ll'} use the
     \code{'classif.LiblineaRL1LogReg'} and the
     \code{'classif.LiblineaRL2LogReg'} Learners respectively. The
     \code{'randomForest'} method is implemented via the
     \code{'classif.randomForest'} Learner.
}
\examples{

    data(siamcat_example)
    # simple working example
    siamcat_validated <- train.model(siamcat_example, method='lasso')

}
\keyword{SIAMCAT}
\keyword{plm.trainer}
